{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "llo-NZN6oD6A"
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3535y48RoXyE"
   },
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = 'cuda:0'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Dr5Avp35oD6D"
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import unsplit.attacks as unsplit\n",
    "from unsplit.models import *\n",
    "from unsplit.util import *\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGlLlNnPoD6E"
   },
   "source": [
    "Change the dataset and split layer values as desired. Dataset can be one of `mnist`, `f_mnist`, while the split depth is between 1 and 6 both for CNN and MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MfP_qHn0oD6F"
   },
   "source": [
    "dataset_name = \"mnist\"\n",
    "architecture = \"mlp\"\n",
    "device = \"cuda\"\n",
    "batch_size = 64\n",
    "\n",
    "n_epochs = 10\n",
    "split_layer = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ta5m0OUCoD6F"
   },
   "source": [
    "def create_models_and_data(dataset_name=\"mnist\", architecture=\"mlp\", batch_size=64, device=\"cuda:0\", seed=0):\n",
    "    assert dataset_name in [\"mnist\", \"f_mnist\"], \"Wrong dataset name. Valid options are 'mnist' and 'f_mnist'.\"\n",
    "    assert architecture in [\"mlp\", \"cnn\"], \"Wrong architecture name. Valid options are 'mlp' and 'cnn'.\"\n",
    "    dataset_creator = datasets.MNIST if dataset_name == \"mnist\" else datasets.FashionMNIST\n",
    "    model_creator = MLP if architecture == \"mlp\" else CNN\n",
    "\n",
    "    trainset = dataset_creator(f'data/{dataset_name}', download=True, train=True, transform=transforms.ToTensor())\n",
    "    testset = dataset_creator(f'data/{dataset_name}', download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    client, server = model_creator().to(device), model_creator().to(device)\n",
    "    return client, server, trainset, testset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wd6tDJm6oD6F"
   },
   "source": [
    "client, server, trainset, testset = create_models_and_data(dataset_name=dataset_name,\n",
    "                                                           architecture=architecture,\n",
    "                                                           batch_size=batch_size,\n",
    "                                                           device=device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgJiw8M6oD6G"
   },
   "source": [
    "## Without Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5d24-27oD6G"
   },
   "source": [
    "The next part trains the client and server models. You can skip this step and launch the attack directly as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GpYekwUsoD6H"
   },
   "source": [
    "def train_client_server(client, server, trainset, testset, split_layer, n_epochs=10, device=\"cuda:0\", batch_size=64):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(testset, shuffle=True, batch_size=64)\n",
    "\n",
    "    client_opt = torch.optim.SGD(client.parameters(), lr=0.001, amsgrad=True)\n",
    "    server_opt = torch.optim.SGD(server.parameters(), lr=0.001, amsgrad=True)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in tqdm(trainloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            client_opt.zero_grad()\n",
    "            server_opt.zero_grad()\n",
    "\n",
    "            client_pred = client(images, end=split_layer)\n",
    "            pred = server(client_pred, start=split_layer+1)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            running_loss += loss\n",
    "\n",
    "            server_opt.step()\n",
    "            client_opt.step()\n",
    "        print(f'Epoch: {epoch} Loss: {running_loss / len(trainloader)} Acc: {get_test_acc(client, server, testloader, split=split_layer)}')\n",
    "    return client, server"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZGJss-voD6H"
   },
   "source": [
    "client, server = train_client_server(client=client, server=server, trainset=trainset, testset=testset,\n",
    "                                     split_layer=split_layer, n_epochs=10, device=device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv62IHQ0oD6I"
   },
   "source": [
    "We are now ready to launch the attack. The next code cell loads `COUNT` many examples from each class of the dataset. Those examples will be used as targets in the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNm9kI1soD6I"
   },
   "source": [
    "COUNT = 1\n",
    "inversion_targets = [get_examples_by_class(testset, i, count=COUNT).to(device) for i in range(10)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2F4SjGLoD6J"
   },
   "source": [
    "display_imagelist(inversion_targets)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xx23fKbJoD6J"
   },
   "source": [
    "main_iters, input_iters, model_iters = 200, 20, 20\n",
    "lambda_l2, lambda_tv = 0.1, 1.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pcVA4a1coD6K"
   },
   "source": [
    "def launch_attack(inversion_targets, client, split_layer, clone_architecture=\"mlp\",\n",
    "                  main_iters=1000, input_iters=100, model_iters=100,\n",
    "                  lambda_tv=0.1, lambda_l2=1, device=\"cuda:0\"):\n",
    "    assert clone_architecture in [\"mlp\", \"cnn\"], \"Wrong architecture name. Valid options are 'mlp' and 'cnn'.\"\n",
    "    clone = MLP() if architecture == \"mlp\" else CNN()\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    reconstructed_images, reconstruction_losses = [], []\n",
    "    cut_layer_training_losses = []\n",
    "    for idx, target in enumerate(inversion_targets):\n",
    "        # obtain client output\n",
    "        with torch.no_grad():\n",
    "            client_out = client(target, end=split_layer)\n",
    "\n",
    "        # perform the attack\n",
    "        target_size = target.size()\n",
    "        reconstructed, cur_loss_arr = unsplit.model_inversion_stealing(\n",
    "            clone, split_layer, client_out, target_size,\n",
    "            main_iters=main_iters, input_iters=input_iters, model_iters=model_iters,\n",
    "            lambda_tv=lambda_tv, lambda_l2=lambda_l2, device=device\n",
    "        )\n",
    "        cut_layer_training_losses.append(cur_loss_arr)\n",
    "\n",
    "        # save result\n",
    "        reconstructed = normalize(reconstructed)\n",
    "        reconstructed_images.append(reconstructed)\n",
    "        reconstruction_loss = mse(reconstructed, target)\n",
    "        reconstruction_losses.append(reconstruction_loss.item())\n",
    "    return clone, reconstructed_images, reconstruction_losses, cut_layer_training_losses"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu9niHXVoD6K"
   },
   "source": [
    "clone, reconstructed_images, reconstruction_losses, cut_layer_training_losses = launch_attack(\n",
    "    inversion_targets, client, split_layer, clone_architecture=architecture,\n",
    "    main_iters=main_iters, input_iters=input_iters, model_iters=model_iters,\n",
    "    lambda_tv=lambda_tv, lambda_l2=lambda_l2, device=device\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUMWrjp0oD6L"
   },
   "source": [
    "display_imagelist(inversion_targets)\n",
    "display_imagelist(reconstructed_images)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NtLEfyUqoD6L"
   },
   "source": [
    "def compute_metrics(inversion_targets, reconstructed_images,\n",
    "                    reconstruction_losses, cut_layer_training_losses,\n",
    "                    compute_fid=False):\n",
    "    reconstruction_mse = np.mean(reconstruction_losses)\n",
    "    cut_layer_mse = np.mean([loss_arr[-1] for loss_arr in cut_layer_training_losses])\n",
    "    print(f\"Recounstruction MSE: {reconstruction_mse:.3f}\")\n",
    "    print(f\"Log10 of cut layer MSE: {np.log10(cut_layer_mse):.3f}\")\n",
    "    if compute_fid:\n",
    "        print(f\"FID: {compute_fid(inversion_targets, reconstructed_images):.1f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oi1D3X7PoD6M"
   },
   "source": [
    "compute_metrics(inversion_targets, reconstructed_images, reconstruction_losses, cut_layer_training_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfUVmkfyoD6M"
   },
   "source": [
    "## With Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvP2Rv5MoD6M"
   },
   "source": [
    "Initialize models and data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1y_X9ANoD6M",
    "outputId": "ac3e1f7a-215a-44e6-9755-50699ead648b"
   },
   "source": [
    "client, server, trainset, testset = create_models_and_data(dataset_name=dataset_name,\n",
    "                                                           architecture=architecture,\n",
    "                                                           batch_size=batch_size,\n",
    "                                                           device=device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pge3CUV7oD6N"
   },
   "source": [
    "Find global $l2$-sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tfxy90vHoD6O"
   },
   "source": [
    "import random\n",
    "\n",
    "def find_l2_sensitivity(trainloader):\n",
    "    total_batches = 0\n",
    "    summed_batch = None\n",
    "    for batch in trainloader:\n",
    "        if summed_batch is None:\n",
    "            summed_batch = torch.zeros_like(batch[0])\n",
    "        if batch[0].size(0) == summed_batch.size(0):\n",
    "            summed_batch += batch[0]\n",
    "            total_batches += 1\n",
    "\n",
    "    averaged_batch = summed_batch / total_batches\n",
    "\n",
    "    averaged_batch_copy = averaged_batch.clone()\n",
    "    s = random.randint(0, 64)\n",
    "    averaged_batch_copy[s] = torch.zeros_like(averaged_batch_copy[s])\n",
    "    gs = torch.norm(averaged_batch - averaged_batch_copy, p='fro').float()\n",
    "    return gs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mkgzrOjoD6O"
   },
   "source": [
    "Now let us adjust distribution parameter $\\sigma$ for $(\\varepsilon, \\delta)$-DP.\n",
    "\n",
    "Code is taken from https://github.com/BorjaBalle/analytic-gaussian-mechanism/blob/master/agm-example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gAzw6Cm7oD6O"
   },
   "source": [
    "from math import exp, sqrt\n",
    "from scipy.special import erf\n",
    "\n",
    "def calibrateAnalyticGaussianMechanism(epsilon, delta, GS, tol = 1.e-12):\n",
    "    \"\"\" Calibrate a Gaussian perturbation for differential privacy using the analytic Gaussian mechanism of [Balle and Wang, ICML'18]\n",
    "\n",
    "    Arguments:\n",
    "    epsilon : target epsilon (epsilon > 0)\n",
    "    delta : target delta (0 < delta < 1)\n",
    "    GS : upper bound on L2 global sensitivity (GS >= 0)\n",
    "    tol : error tolerance for binary search (tol > 0)\n",
    "\n",
    "    Output:\n",
    "    sigma : standard deviation of Gaussian noise needed to achieve (epsilon,delta)-DP under global sensitivity GS\n",
    "    \"\"\"\n",
    "\n",
    "    def Phi(t):\n",
    "        return 0.5*(1.0 + erf(float(t)/sqrt(2.0)))\n",
    "\n",
    "    def caseA(epsilon,s):\n",
    "        return Phi(sqrt(epsilon*s)) - exp(epsilon)*Phi(-sqrt(epsilon*(s+2.0)))\n",
    "\n",
    "    def caseB(epsilon,s):\n",
    "        return Phi(-sqrt(epsilon*s)) - exp(epsilon)*Phi(-sqrt(epsilon*(s+2.0)))\n",
    "\n",
    "    def doubling_trick(predicate_stop, s_inf, s_sup):\n",
    "        while(not predicate_stop(s_sup)):\n",
    "            s_inf = s_sup\n",
    "            s_sup = 2.0*s_inf\n",
    "        return s_inf, s_sup\n",
    "\n",
    "    def binary_search(predicate_stop, predicate_left, s_inf, s_sup):\n",
    "        s_mid = s_inf + (s_sup-s_inf)/2.0\n",
    "        while(not predicate_stop(s_mid)):\n",
    "            if (predicate_left(s_mid)):\n",
    "                s_sup = s_mid\n",
    "            else:\n",
    "                s_inf = s_mid\n",
    "            s_mid = s_inf + (s_sup-s_inf)/2.0\n",
    "        return s_mid\n",
    "\n",
    "    delta_thr = caseA(epsilon, 0.0)\n",
    "\n",
    "    if (delta == delta_thr):\n",
    "        alpha = 1.0\n",
    "\n",
    "    else:\n",
    "        if (delta > delta_thr):\n",
    "            predicate_stop_DT = lambda s : caseA(epsilon, s) >= delta\n",
    "            function_s_to_delta = lambda s : caseA(epsilon, s)\n",
    "            predicate_left_BS = lambda s : function_s_to_delta(s) > delta\n",
    "            function_s_to_alpha = lambda s : sqrt(1.0 + s/2.0) - sqrt(s/2.0)\n",
    "\n",
    "        else:\n",
    "            predicate_stop_DT = lambda s : caseB(epsilon, s) <= delta\n",
    "            function_s_to_delta = lambda s : caseB(epsilon, s)\n",
    "            predicate_left_BS = lambda s : function_s_to_delta(s) < delta\n",
    "            function_s_to_alpha = lambda s : sqrt(1.0 + s/2.0) + sqrt(s/2.0)\n",
    "\n",
    "        predicate_stop_BS = lambda s : abs(function_s_to_delta(s) - delta) <= tol\n",
    "\n",
    "        s_inf, s_sup = doubling_trick(predicate_stop_DT, 0.0, 1.0)\n",
    "        s_final = binary_search(predicate_stop_BS, predicate_left_BS, s_inf, s_sup)\n",
    "        alpha = function_s_to_alpha(s_final)\n",
    "\n",
    "    sigma = alpha*GS/sqrt(2.0*epsilon)\n",
    "\n",
    "    return sigma"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hyqzl3T7oD6P"
   },
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "class CustomNormalDistribution(torch.nn.Module):\n",
    "    def __init__(self, shape, mean, std):\n",
    "        super(CustomNormalDistribution, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.mean = torch.nn.Parameter(torch.tensor(mean))\n",
    "        self.std = torch.nn.Parameter(torch.tensor(std))\n",
    "\n",
    "    def forward(self):\n",
    "        return dist.Normal(self.mean, self.std)\n",
    "\n",
    "\n",
    "def noisybatch(images, mean=0.0, std=1.0):\n",
    "    shape = images.shape\n",
    "    custom_dist = CustomNormalDistribution(shape, mean, std)\n",
    "    sample = custom_dist().rsample()\n",
    "    return sample"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_5ul6-ZvoD6P"
   },
   "source": [
    "def train_client_server_noise(client, server, trainset, testset, split_layer, epsilon, delta, n_epochs=10, device=\"cuda:0\", batch_size=64):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(testset, shuffle=True, batch_size=64)\n",
    "\n",
    "    client_opt = torch.optim.Adam(client.parameters(), lr=0.001, amsgrad=True)\n",
    "    server_opt = torch.optim.Adam(server.parameters(), lr=0.001, amsgrad=True)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    gs = find_l2_sensitivity(trainloader)\n",
    "    print(r\"The global $\\ell_2$ sensitivity is:\", gs)\n",
    "    sigma = calibrateAnalyticGaussianMechanism(epsilon=epsilon, delta=delta, GS=gs)\n",
    "    print(r\"The $\\sigma$ for noise is:\", sigma)\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in tqdm(trainloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            client_opt.zero_grad()\n",
    "            server_opt.zero_grad()\n",
    "\n",
    "            noise = noisybatch(images, mean=0.0, std=sigma)\n",
    "            client_pred = client(torch.add(images, noise), end=split_layer)\n",
    "            pred = server(client_pred, start=split_layer+1)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            running_loss += loss\n",
    "\n",
    "            server_opt.step()\n",
    "            client_opt.step()\n",
    "        print(f'Epoch: {epoch} Loss: {running_loss / len(trainloader)} Acc: {get_test_acc(client, server, testloader, split=split_layer)}')\n",
    "    return client, server, sigma"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXeIiHA5oD6P"
   },
   "source": [
    "You may adjust your changes into ` epsilon`  and ` delta` .\n",
    "Also, do not hesitate to increase the number of epochs, since the noise may slow down the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdFlSUIVoD6P",
    "outputId": "9cacec9c-711e-4a7d-d542-3249d137c8f6"
   },
   "source": [
    "client, server, sigma = train_client_server_noise(client=client, server=server, trainset=trainset, testset=testset,\n",
    "                                     split_layer=split_layer, epsilon=6, delta=0.5,  n_epochs=10, device=device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0MVb2cQoD6P"
   },
   "source": [
    "Now let us see how adding noise affects on attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gnDizqeroD6Q"
   },
   "source": [
    "COUNT = 1\n",
    "inversion_targets = [get_examples_by_class(testset, c, count=COUNT) for c in range(10)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "dECQoJr1oD6Q"
   },
   "source": [
    "noised_inversion_targets = inversion_targets\n",
    "inversion_targets[0].shape\n",
    "for c in range(10):\n",
    "    noise = noisybatch(inversion_targets[c], mean=0.0, std=sigma)\n",
    "    noised_inversion_targets[c] = torch.add(inversion_targets[c], noise).to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "aOi3sUVkoD6Q",
    "outputId": "6d37744a-3f6e-47d2-c1a8-e21b22b33659"
   },
   "source": [
    "display_imagelist(noised_inversion_targets)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2S4Szuz5oD6Q"
   },
   "source": [
    "main_iters, input_iters, model_iters = 200, 20, 20\n",
    "lambda_l2, lambda_tv = 0.1, 1.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q926c0NToD6Q",
    "outputId": "33f70dde-5042-4448-accd-4e447f6297f6"
   },
   "source": [
    "clone, reconstructed_images, reconstruction_losses, cut_layer_training_losses = launch_attack(\n",
    "    noised_inversion_targets, client, split_layer, clone_architecture=architecture,\n",
    "    main_iters=main_iters, input_iters=input_iters, model_iters=model_iters,\n",
    "    lambda_tv=lambda_tv, lambda_l2=lambda_l2, device=device\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "lu6sle2XoD6Q",
    "outputId": "14beaba3-a1b1-4d08-86f4-64de7a65c7a4"
   },
   "source": [
    "display_imagelist(noised_inversion_targets)\n",
    "display_imagelist(reconstructed_images)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFma3RsEoD6Q",
    "outputId": "7416e0ab-e31a-4933-dc7c-152ae5c6dc09"
   },
   "source": [
    "compute_metrics(noised_inversion_targets, reconstructed_images, reconstruction_losses, cut_layer_training_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ckm-EMXaoD6R",
    "outputId": "afd9983e-a59f-40b9-a22a-750be217fc29"
   },
   "source": [
    "compute_metrics(noised_inversion_targets, reconstructed_images, reconstruction_losses, cut_layer_training_losses)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
